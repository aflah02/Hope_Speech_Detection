{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.char as nac\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.0kB/s]\n",
      "c:\\Kyode\\clg\\ml\\ML_Project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gener\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:01<00:00, 224kB/s]  \n",
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 358kB/s]  \n",
      "Downloading: 100%|██████████| 440M/440M [00:33<00:00, 13.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "ctx_aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"..\\\\Data\\\\PreprocessedData\\\\english_train_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>these tiktoks radiate gay chaotic energy and i...</td>\n",
       "      <td>Non_hope_speech</td>\n",
       "      <td>these tiktoks radiate gay chaotic energy and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@Champions Again He got killed for using false...</td>\n",
       "      <td>Non_hope_speech</td>\n",
       "      <td>&lt;user&gt; again he got killed for using false money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It's not that all lives don't matter</td>\n",
       "      <td>Non_hope_speech</td>\n",
       "      <td>its not that all lives dont matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Is it really that difficult to understand? Bla...</td>\n",
       "      <td>Non_hope_speech</td>\n",
       "      <td>is it really that difficult to understand blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whenever we say black isn't that racists?  Why...</td>\n",
       "      <td>Non_hope_speech</td>\n",
       "      <td>whenever we say black isnt that racists why do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                  preprocessed_text\n",
       "0           0  ...  these tiktoks radiate gay chaotic energy and i...\n",
       "1           1  ...   <user> again he got killed for using false money\n",
       "2           2  ...                 its not that all lives dont matter\n",
       "3           3  ...  is it really that difficult to understand blac...\n",
       "4           4  ...  whenever we say black isnt that racists why do...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Hope_speech         1962\n",
       "Non_hope_speech    20778\n",
       "not-English           22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope = df_train[df_train.label==\"Hope_speech\"][\"preprocessed_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['network engineer here 23 and currently working as an instructor teaching men and women looking to be in it = next i want to teach at a university',\n",
       "       'im still hiding my gender to my parents and they dont know im dating someone my friends knows already about my gender and they are very supportive of it and im very thankful to find true friends like them',\n",
       "       'all lives matter without that we never have peace so to me forever all lives matter',\n",
       "       ...,\n",
       "       'i know that was so sweet of the boy to to say hope he knows is a good person',\n",
       "       'i could maybe be sympathetic if they were less vague all i hear is them ascribing sinister motives to people who seem like they are just being overly friendly nerdsnand these testimonials right before the statstics on women engineers in silicon valley seem to imply that the reason that there are less women in tech there is because it is a hostile environment for women but step in your typical engineering classroom in america and then tell me that there are as many women interested in engineering as men a gender inbalance does not automatically mean discrimination',\n",
       "       'this is inspiring im a mechanical engineering student and i needed this so bad'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1962/1962 [33:25<00:00,  1.02s/it] \n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for each in tqdm(hope):\n",
    "    x.append(ctx_aug.augment(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_aug = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1962/1962 [00:07<00:00, 272.79it/s]\n"
     ]
    }
   ],
   "source": [
    "x2 = []\n",
    "for each in tqdm(hope):\n",
    "    x2.append(syn_aug.augment(each, n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array(x2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.append(x, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this be inspiring im a mechanically skillful applied science student and i postulate this so bad',\n",
       " 'this is inspiring im a mechanically skillful technology student and i postulate this thence bad')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1], x[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5886,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_aug = naw.RandomWordAug(\"swap\", aug_max = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3924/3924 [00:01<00:00, 3740.60it/s]\n"
     ]
    }
   ],
   "source": [
    "x3 = []\n",
    "for each in tqdm(x2):\n",
    "    x3.append(swap_aug.augment(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.array(x3, dtype = object).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.append(x3, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9810,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_aug = naw.RandomWordAug(aug_max = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9810/9810 [00:01<00:00, 7643.13it/s]\n"
     ]
    }
   ],
   "source": [
    "x4 = []\n",
    "for each in tqdm(x3):\n",
    "    x4.append(delete_aug.augment(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = np.array(x4).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9810,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = np.append(x4, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19620,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.DataFrame({\"augmented_text\": x4, \"label\": \"Hope_speech\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"augmented_text\"] = df_train[\"preprocessed_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gener\\AppData\\Local\\Temp\\ipykernel_26816\\2892258247.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_aug = df_aug.append(df_train[[\"augmented_text\", \"label\"]])\n"
     ]
    }
   ],
   "source": [
    "df_aug = df_aug.append(df_train[[\"augmented_text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42382, 2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.to_csv(\"..//Data//AugmentedData//english_train_augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f02a134849fd5c5f66d44739b03caad7c6758a3d768c4bdabdf36d26611ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
