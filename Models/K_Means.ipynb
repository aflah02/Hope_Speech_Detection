{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_loader import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, dev_labels, test_labels = load_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllScores(y_pred_train, y_pred_dev, y_pred_test):\n",
    "    print(\"Accuracy Train: \", accuracy_score(train_labels, y_pred_train))\n",
    "    print(\"Accuracy Dev: \", accuracy_score(dev_labels, y_pred_dev))\n",
    "    print(\"Accuracy Test: \", accuracy_score(test_labels, y_pred_test))\n",
    "    print(\"F1 Train: \", f1_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"F1 Dev: \", f1_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"F1 Test: \", f1_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Precision Train: \", precision_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Precision Dev: \", precision_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Precision Test: \", precision_score(test_labels, y_pred_test, average='macro'))\n",
    "    print(\"Recall Train: \", recall_score(train_labels, y_pred_train, average='macro'))\n",
    "    print(\"Recall Dev: \", recall_score(dev_labels, y_pred_dev, average='macro'))\n",
    "    print(\"Recall Test: \", recall_score(test_labels, y_pred_test, average='macro'))\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix Train: \")\n",
    "    print(confusion_matrix(train_labels, y_pred_train))\n",
    "    print(\"Confusion Matrix Dev: \")\n",
    "    print(confusion_matrix(dev_labels, y_pred_dev))\n",
    "    print(\"Confusion Matrix Test: \")\n",
    "    print(confusion_matrix(test_labels, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_replacement = {\n",
    "    'Hope_speech': 0,\n",
    "    'Non_hope_speech': 1,\n",
    "    'not-English': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace labels with numbers\n",
    "train_labels = [label_replacement[label] for label in train_labels]\n",
    "dev_labels = [label_replacement[label] for label in dev_labels]\n",
    "test_labels = [label_replacement[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt25_train, gt25_dev, gt25_test = load_glove_twitter_25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "gt25_train = np.nan_to_num(gt25_train)\n",
    "gt25_dev = np.nan_to_num(gt25_dev)\n",
    "gt25_test = np.nan_to_num(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(gt25_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(gt25_train)\n",
    "dev_preds = k_means.predict(gt25_dev)\n",
    "test_preds = k_means.predict(gt25_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.18153062121078992\n",
      "Accuracy Dev:  0.17622230038691522\n",
      "Accuracy Test:  0.18657765284609978\n",
      "F1 Train:  0.147388082222974\n",
      "F1 Dev:  0.14283631492082952\n",
      "F1 Test:  0.15016522555352096\n",
      "Precision Train:  0.3622779694158384\n",
      "Precision Dev:  0.36097332451499115\n",
      "Precision Test:  0.36523584905660383\n",
      "Recall Train:  0.32618430603949866\n",
      "Recall Dev:  0.2107389958708279\n",
      "Recall Test:  0.23452063247204014\n",
      "Confusion Matrix Train: \n",
      "[[1099   70  793]\n",
      " [8657 3027 9094]\n",
      " [   4   12    6]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 133    8  131]\n",
      " [1083  368 1118]\n",
      " [   0    2    0]]\n",
      "Confusion Matrix Test: \n",
      "[[ 138    5  107]\n",
      " [1080  393 1120]\n",
      " [   1    2    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft300_train, ft300_dev, ft300_test = load_fasttext_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "ft300_train = np.nan_to_num(ft300_train)\n",
    "ft300_dev = np.nan_to_num(ft300_dev)\n",
    "ft300_test = np.nan_to_num(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(ft300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(ft300_train)\n",
    "dev_preds = k_means.predict(ft300_dev)\n",
    "test_preds = k_means.predict(ft300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.09138037079342765\n",
      "Accuracy Dev:  0.09672880759760816\n",
      "Accuracy Test:  0.08995080815179199\n",
      "F1 Train:  0.09425327100502011\n",
      "F1 Dev:  0.10600388101230933\n",
      "F1 Test:  0.09230425202211685\n",
      "Precision Train:  0.34223776163350256\n",
      "Precision Dev:  0.3454517868120958\n",
      "Precision Test:  0.34024789171993636\n",
      "Recall Train:  0.3564043982385188\n",
      "Recall Dev:  0.30960108839176\n",
      "Recall Test:  0.34402810986844923\n",
      "Confusion Matrix Train: \n",
      "[[  624   115  1223]\n",
      " [ 5633  1441 13704]\n",
      " [    7     0    15]]\n",
      "Confusion Matrix Dev: \n",
      "[[  98   18  156]\n",
      " [ 663  176 1730]\n",
      " [   1    0    1]]\n",
      "Confusion Matrix Test: \n",
      "[[  74   15  161]\n",
      " [ 691  180 1722]\n",
      " [   1    0    2]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v300_train, w2v300_dev, w2v300_test = load_word2vec_300()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all NaN values to 0\n",
    "w2v300_train = np.nan_to_num(w2v300_train)\n",
    "w2v300_dev = np.nan_to_num(w2v300_dev)\n",
    "w2v300_test = np.nan_to_num(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(w2v300_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(w2v300_train)\n",
    "dev_preds = k_means.predict(w2v300_dev)\n",
    "test_preds = k_means.predict(w2v300_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.601704595378262\n",
      "Accuracy Dev:  0.5993668659866338\n",
      "Accuracy Test:  0.5948699929725931\n",
      "F1 Train:  0.259209304347983\n",
      "F1 Dev:  0.2591562570724056\n",
      "F1 Test:  0.25488634436540464\n",
      "Precision Train:  0.3066791913582484\n",
      "Precision Dev:  0.30496220828068415\n",
      "Precision Test:  0.30158778930235264\n",
      "Recall Train:  0.3596312774201172\n",
      "Recall Dev:  0.3909218319480381\n",
      "Recall Test:  0.4408071303080945\n",
      "Confusion Matrix Train: \n",
      "[[   24  1452   486]\n",
      " [ 1540 13663  5575]\n",
      " [    1    12     9]]\n",
      "Confusion Matrix Dev: \n",
      "[[   3  195   74]\n",
      " [ 178 1700  691]\n",
      " [   1    0    1]]\n",
      "Confusion Matrix Test: \n",
      "[[   1  193   56]\n",
      " [ 194 1690  709]\n",
      " [   0    1    2]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF PCA (1000 Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_train, tfidf_pca_dev, tfidf_pca_test = load_tfidf_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(tfidf_pca_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(tfidf_pca_train)\n",
    "dev_preds = k_means.predict(tfidf_pca_dev)\n",
    "test_preds = k_means.predict(tfidf_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.13904753536596082\n",
      "Accuracy Dev:  0.13823425958494548\n",
      "Accuracy Test:  0.15038650737877723\n",
      "F1 Train:  0.1378300930462873\n",
      "F1 Dev:  0.14548665436659838\n",
      "F1 Test:  0.15596801860050574\n",
      "Precision Train:  0.3566092863759667\n",
      "Precision Dev:  0.36888950434125073\n",
      "Precision Test:  0.37446859668065735\n",
      "Recall Train:  0.36377233556457167\n",
      "Recall Dev:  0.2810823239377495\n",
      "Recall Test:  0.45904974932510606\n",
      "Confusion Matrix Train: \n",
      "[[  362   318  1282]\n",
      " [ 1736  2786 16256]\n",
      " [    1     4    17]]\n",
      "Confusion Matrix Dev: \n",
      "[[  58   36  178]\n",
      " [ 226  334 2009]\n",
      " [   1    0    1]]\n",
      "Confusion Matrix Test: \n",
      "[[  59   34  157]\n",
      " [ 226  366 2001]\n",
      " [   0    0    3]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(train)\n",
    "dev_preds = k_means.predict(dev)\n",
    "test_preds = k_means.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.18153062121078992\n",
      "Accuracy Dev:  0.1790362293352093\n",
      "Accuracy Test:  0.18587491215741392\n",
      "F1 Train:  0.14011556969253425\n",
      "F1 Dev:  0.14181942622918112\n",
      "F1 Test:  0.1460971673361054\n",
      "Precision Train:  0.30551191414821555\n",
      "Precision Dev:  0.3050709246535144\n",
      "Precision Test:  0.3132600246969472\n",
      "Recall Train:  0.27789482147876393\n",
      "Recall Dev:  0.30709095627351757\n",
      "Recall Test:  0.4852860264815529\n",
      "Confusion Matrix Train: \n",
      "[[  490   747   725]\n",
      " [ 5069  3633 12076]\n",
      " [    4     9     9]]\n",
      "Confusion Matrix Dev: \n",
      "[[  68   99  105]\n",
      " [ 623  440 1506]\n",
      " [   1    0    1]]\n",
      "Confusion Matrix Test: \n",
      "[[  70   86   94]\n",
      " [ 655  456 1482]\n",
      " [   0    0    3]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Faster PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_fast_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(train)\n",
    "dev_preds = k_means.predict(dev)\n",
    "test_preds = k_means.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.25498638081012215\n",
      "Accuracy Dev:  0.25606753429475904\n",
      "Accuracy Test:  0.26317638791286013\n",
      "F1 Train:  0.16236791928746389\n",
      "F1 Dev:  0.16451878372140416\n",
      "F1 Test:  0.16584946491566122\n",
      "Precision Train:  0.3232669227808397\n",
      "Precision Dev:  0.3218084979226132\n",
      "Precision Test:  0.32098064891604833\n",
      "Recall Train:  0.340719445147117\n",
      "Recall Dev:  0.20951207458460222\n",
      "Recall Test:  0.20953438745340017\n",
      "Confusion Matrix Train: \n",
      "[[  724   490   748]\n",
      " [12077  5071  3630]\n",
      " [    9     4     9]]\n",
      "Confusion Matrix Dev: \n",
      "[[ 105   68   99]\n",
      " [1506  623  440]\n",
      " [   1    1    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  94   70   86]\n",
      " [1483  655  455]\n",
      " [   3    0    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_no_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(train)\n",
    "dev_preds = k_means.predict(dev)\n",
    "test_preds = k_means.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.26276249890167824\n",
      "Accuracy Dev:  0.2655645444952515\n",
      "Accuracy Test:  0.26879831342234717\n",
      "F1 Train:  0.16384026720836667\n",
      "F1 Dev:  0.16543060063977458\n",
      "F1 Test:  0.16483106838829087\n",
      "Precision Train:  0.31950737335931884\n",
      "Precision Dev:  0.31541708431270415\n",
      "Precision Test:  0.3132002345714507\n",
      "Recall Train:  0.3390013963269374\n",
      "Recall Dev:  0.18671767071951395\n",
      "Recall Test:  0.1874955649826456\n",
      "Confusion Matrix Train: \n",
      "[[  596   546   820]\n",
      " [11501  5375  3902]\n",
      " [    8     4    10]]\n",
      "Confusion Matrix Dev: \n",
      "[[  81   80  111]\n",
      " [1431  674  464]\n",
      " [   1    1    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  74   85   91]\n",
      " [1429  691  473]\n",
      " [   3    0    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer Better PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = load_sent_trans_better_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3, random_state=0).fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = k_means.predict(train)\n",
    "dev_preds = k_means.predict(dev)\n",
    "test_preds = k_means.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  0.2627185660311045\n",
      "Accuracy Dev:  0.2655645444952515\n",
      "Accuracy Test:  0.26879831342234717\n",
      "F1 Train:  0.1637930676291687\n",
      "F1 Dev:  0.16543060063977458\n",
      "F1 Test:  0.16486310277070693\n",
      "Precision Train:  0.3194769438592779\n",
      "Precision Dev:  0.31541708431270415\n",
      "Precision Test:  0.31322201506178254\n",
      "Recall Train:  0.33867764960549235\n",
      "Recall Dev:  0.18671767071951395\n",
      "Recall Test:  0.1874955649826456\n",
      "Confusion Matrix Train: \n",
      "[[  594   546   822]\n",
      " [11487  5376  3915]\n",
      " [    8     4    10]]\n",
      "Confusion Matrix Dev: \n",
      "[[  81   80  111]\n",
      " [1431  674  464]\n",
      " [   1    1    0]]\n",
      "Confusion Matrix Test: \n",
      "[[  74   85   91]\n",
      " [1427  691  475]\n",
      " [   3    0    0]]\n"
     ]
    }
   ],
   "source": [
    "computeAllScores(train_preds, dev_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
